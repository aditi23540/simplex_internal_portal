{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c107151",
   "metadata": {},
   "source": [
    "# JSON COMPILER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8034d054",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from collections import defaultdict\n",
    "\n",
    "# === Configuration ===\n",
    "json_directory = r\"json\"\n",
    "json_files = [\n",
    "    \"employee_master\", \"emp_references\", \"emp_language\", \"emp_hobbies\",\n",
    "    \"emp_family\", \"emp_experience\", \"emp_education\", \"emp_documents\",\n",
    "    \"emp_curricular\", \"emp_contact\", \"emp_certification\"\n",
    "]\n",
    "\n",
    "employee_data = defaultdict(lambda: defaultdict(list))\n",
    "\n",
    "print(\"🔍 Starting file processing...\\n\")\n",
    "\n",
    "for file_name in json_files:\n",
    "    file_path = os.path.join(json_directory, file_name + \".json\")\n",
    "    if not os.path.exists(file_path):\n",
    "        print(f\"❌ Missing file: {file_path}\")\n",
    "        continue\n",
    "\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        try:\n",
    "            content = json.load(f)\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"❌ JSON decoding failed for {file_name}: {e}\")\n",
    "            continue\n",
    "\n",
    "    # phpMyAdmin export structure\n",
    "    data_section = None\n",
    "    for section in content:\n",
    "        if section.get(\"type\") == \"table\" and \"data\" in section:\n",
    "            data_section = section[\"data\"]\n",
    "            break\n",
    "\n",
    "    if not data_section:\n",
    "        print(f\"⚠️ No 'data' found in {file_name}\")\n",
    "        continue\n",
    "\n",
    "    section_name = file_name\n",
    "    count = 0\n",
    "\n",
    "    for i, record in enumerate(data_section):\n",
    "        emp_id = record.get(\"emp_id\") or record.get(\"empid\")\n",
    "        if not emp_id:\n",
    "            print(f\"⚠️ No emp_id in record {i} of {file_name}\")\n",
    "            continue\n",
    "        employee_data[emp_id][section_name].append(record)\n",
    "        count += 1\n",
    "\n",
    "    print(f\"✅ Loaded {count} records from {file_name}\")\n",
    "\n",
    "# Flatten employee_master (optional)\n",
    "for emp_id, sections in employee_data.items():\n",
    "    if \"employee_master\" in sections and isinstance(sections[\"employee_master\"], list):\n",
    "        sections[\"employee_master\"] = sections[\"employee_master\"][0]\n",
    "\n",
    "# Save final output\n",
    "output_path = os.path.join(json_directory, \"full_employee_json_data.json\")\n",
    "with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(employee_data, f, indent=4)\n",
    "\n",
    "print(f\"\\n💾 Final merged JSON saved to: {output_path}\")\n",
    "\n",
    "# Optional: show one sample record\n",
    "if employee_data:\n",
    "    first_emp_id = next(iter(employee_data))\n",
    "    print(f\"\\n🔎 Sample record for emp_id = {first_emp_id}:\")\n",
    "    print(json.dumps(employee_data[first_emp_id], indent=2))\n",
    "else:\n",
    "    print(\"⚠️ No employee data found. Check JSON files again.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "897cb0b5",
   "metadata": {},
   "source": [
    "# JSON TO MYSQL Migrator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4aaf359",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import mysql.connector\n",
    "from datetime import datetime\n",
    "import os\n",
    "import glob\n",
    "\n",
    "# --- Database Configuration ---\n",
    "# !!! REPLACE WITH YOUR ACTUAL DATABASE CREDENTIALS !!!\n",
    "db_config = {\n",
    "    'host': 'localhost',\n",
    "    'user': 'root',\n",
    "    'password': '',\n",
    "    'database': 'user_master_db' # Make sure this matches your new DB name\n",
    "}\n",
    "\n",
    "# --- Database Reset Function ---\n",
    "def reset_database_tables():\n",
    "    \"\"\"\n",
    "    Truncates all relevant tables and resets their AUTO_INCREMENT counters to 1.\n",
    "    \"\"\"\n",
    "    tables_to_reset = [\n",
    "        'user_work_experience',\n",
    "        'user_references',\n",
    "        'user_languages',\n",
    "        'user_it_details',\n",
    "        'user_hr_details',\n",
    "        'user_education',\n",
    "        'user_certifications',\n",
    "        'user_bank_details',\n",
    "        'spouse_details',\n",
    "        'parent_details',\n",
    "        'users' \n",
    "    ]\n",
    "    \n",
    "    conn = None\n",
    "    try:\n",
    "        conn = get_db_connection()\n",
    "        if not conn:\n",
    "            print(\"Error: Could not connect to the database to perform reset.\")\n",
    "            return False\n",
    "            \n",
    "        cursor = conn.cursor()\n",
    "        \n",
    "        print(\"\\n--- Resetting Database Tables ---\")\n",
    "        \n",
    "        cursor.execute(\"SET FOREIGN_KEY_CHECKS = 0;\")\n",
    "        \n",
    "        for table in tables_to_reset:\n",
    "            try:\n",
    "                print(f\"Resetting table: {table}...\")\n",
    "                cursor.execute(f\"TRUNCATE TABLE {table};\")\n",
    "                cursor.execute(f\"ALTER TABLE {table} AUTO_INCREMENT = 1;\")\n",
    "            except mysql.connector.Error as err:\n",
    "                if \"Unknown table\" in str(err):\n",
    "                     print(f\"  - Warning: Table '{table}' not found. Skipping.\")\n",
    "                else:\n",
    "                    raise \n",
    "        \n",
    "        conn.commit()\n",
    "        print(\"Database tables have been reset successfully.\")\n",
    "        return True\n",
    "\n",
    "    except mysql.connector.Error as err:\n",
    "        print(f\"Database error during reset: {err}\")\n",
    "        if conn: conn.rollback()\n",
    "        return False\n",
    "    finally:\n",
    "        if conn and conn.is_connected():\n",
    "            cursor.execute(\"SET FOREIGN_KEY_CHECKS = 1;\")\n",
    "            cursor.close()\n",
    "            conn.close()\n",
    "\n",
    "# --- Helper Functions ---\n",
    "def get_db_connection():\n",
    "    try:\n",
    "        conn = mysql.connector.connect(**db_config)\n",
    "        return conn\n",
    "    except mysql.connector.Error as err:\n",
    "        print(f\"Error connecting to MySQL: {err}\")\n",
    "        return None\n",
    "\n",
    "def format_date(date_str, input_formats=['%Y-%m-%d', '%d-%m-%Y', '%m/%d/%Y', '%d-%b-%Y %H:%M:%S']): \n",
    "    if not date_str: return None\n",
    "    for fmt in input_formats:\n",
    "        try:\n",
    "            dt_obj = datetime.strptime(str(date_str), fmt)\n",
    "            return dt_obj.strftime('%Y-%m-%d')\n",
    "        except (ValueError, TypeError):\n",
    "            continue\n",
    "    return None\n",
    "\n",
    "def to_boolean(value_str, true_val_primary=\"1\", true_val_alternates=None):\n",
    "    if value_str is None: return None \n",
    "    s_input = str(value_str).strip().lower()\n",
    "    if not s_input: return None\n",
    "    true_conditions = [str(true_val_primary).lower()] \n",
    "    if true_val_alternates:\n",
    "        for alt in true_val_alternates:\n",
    "            if alt is not None and isinstance(alt, str):\n",
    "                true_conditions.append(alt.lower())\n",
    "    return 1 if s_input in true_conditions else 0\n",
    "\n",
    "def get_lookup_value(id_value, lookup_type, default_if_not_found=None):\n",
    "    if not id_value: return default_if_not_found\n",
    "    if lookup_type == 'country':\n",
    "        if str(id_value) == \"101\": return \"India\"\n",
    "    elif lookup_type == 'state':\n",
    "        if str(id_value) == \"7\": return \"Chhattisgarh\" \n",
    "    return default_if_not_found if default_if_not_found is not None else str(id_value)\n",
    "\n",
    "def sanitize_filename(filename):\n",
    "    if not filename: return None\n",
    "    sane_filename = \"\".join(c if c.isalnum() or c in ['.', '_', '-'] else '_' for c in str(filename))\n",
    "    sane_filename = \"_\".join(filter(None, sane_filename.split('_')))\n",
    "    sane_filename = \".\".join(filter(None, sane_filename.split('.'))) \n",
    "    if len(sane_filename) > 200: \n",
    "        name, ext = os.path.splitext(sane_filename)\n",
    "        sane_filename = name[:200-len(ext)] + ext\n",
    "    return sane_filename\n",
    "\n",
    "def find_original_filename_from_emp_docs(emp_documents, old_internal_emp_id_for_lookup, doc_type_in_emp_docs, related_old_id=None, old_table_name=None):\n",
    "    if not emp_documents: return None\n",
    "    for doc in emp_documents:\n",
    "        if str(doc.get('empid')) == str(old_internal_emp_id_for_lookup) and doc.get('document_name') == doc_type_in_emp_docs:\n",
    "            if related_old_id is not None and str(doc.get('field_id')) != str(related_old_id):\n",
    "                continue\n",
    "            if old_table_name is not None and doc.get('field_table_name') != old_table_name:\n",
    "                continue\n",
    "            original_filename = doc.get('document')\n",
    "            if original_filename and str(original_filename).strip():\n",
    "                return str(original_filename).strip() \n",
    "    return None\n",
    "\n",
    "# --- Main Data Processing Function ---\n",
    "def migrate_employee_data(all_data_for_single_employee): \n",
    "    conn = get_db_connection()\n",
    "    if not conn: return False\n",
    "    cursor = conn.cursor(dictionary=True) \n",
    "    new_user_id = None \n",
    "\n",
    "    data = all_data_for_single_employee.get('employee_master') \n",
    "    if not data or not isinstance(data, dict): \n",
    "        print(f\"Error: employee_master data is missing or not a dictionary.\")\n",
    "        return False\n",
    "        \n",
    "    # Corrected keys are used to retrieve data from the JSON\n",
    "    emp_contact_list = all_data_for_single_employee.get('emp_contact', [])\n",
    "    emp_family_list = all_data_for_single_employee.get('emp_family', [])\n",
    "    emp_education_list = all_data_for_single_employee.get('emp_education', [])\n",
    "    emp_experience_list = all_data_for_single_employee.get('emp_experience', []) \n",
    "    emp_languages_list = all_data_for_single_employee.get('emp_language', []) # CORRECTED KEY\n",
    "    emp_references_list = all_data_for_single_employee.get('emp_references', []) # CORRECTED KEY\n",
    "    emp_documents_list = all_data_for_single_employee.get('emp_documents', [])\n",
    "    emp_hobbies_list = all_data_for_single_employee.get('emp_hobbies', [])\n",
    "    emp_curricular_list = all_data_for_single_employee.get('emp_curricular', [])\n",
    "    emp_certification_list = all_data_for_single_employee.get('emp_certification', [])\n",
    "    \n",
    "    old_internal_emp_id = data.get('emp_id') \n",
    "    employee_id_ascent_val = data.get('User_id') \n",
    "\n",
    "    if not old_internal_emp_id or not str(old_internal_emp_id).strip():\n",
    "        print(f\"Error: 'emp_id' is missing or invalid in employee_master data.\")\n",
    "        return False\n",
    "\n",
    "    print(f\"\\n--- Processing records for old_emp_id: {old_internal_emp_id} ---\")\n",
    "\n",
    "    try:\n",
    "        contact_info = emp_contact_list[0] if emp_contact_list else {}\n",
    "\n",
    "        pan_available_bool = 1 if data.get('pan_no') and str(data.get('pan_no')).strip() else 0\n",
    "        aadhar_available_bool = to_boolean(data.get('aadhaar_card'), true_val_primary=\"Available\")\n",
    "        if aadhar_available_bool is None : aadhar_available_bool = 0 \n",
    "        dl_available_bool = 1 if data.get('licence_no') and str(data.get('licence_no')).strip() else 0\n",
    "        passport_available_bool = 1 if data.get('passport_no') and str(data.get('passport_no')).strip() else 0\n",
    "        has_past_experience_bool = to_boolean(data.get('past_experience'), \"1\")\n",
    "        has_pf_account_bool = 1 if (data.get('pf_account') and str(data.get('pf_account')).strip()) or \\\n",
    "                                     (data.get('uan_no') and str(data.get('uan_no')).strip()) else 0\n",
    "        medical_disability_exists_bool = to_boolean(data.get('medical_disability_status'), true_val_primary=\"no\", true_val_alternates=[\"yes\"]) \n",
    "        if medical_disability_exists_bool == 0 and str(data.get('medical_disability_status')).strip().lower() == \"no\": medical_disability_exists_bool = 0\n",
    "        elif medical_disability_exists_bool == 1 and str(data.get('medical_disability_status')).strip().lower() == \"yes\": medical_disability_exists_bool = 1\n",
    "        else: medical_disability_exists_bool = 0 if medical_disability_exists_bool is None else medical_disability_exists_bool\n",
    "        prev_employer_liability_exists_bool = to_boolean(data.get('any_libility'), true_val_primary=\"yes\")\n",
    "        worked_simplex_group_bool = to_boolean(data.get('applied_before'), true_val_primary=\"yes\")\n",
    "        agree_posted_anywhere_india_bool = to_boolean(data.get('agree_posted_anywhere'), true_val_primary=\"yes\")\n",
    "        declaration_agreed_bool = 1 \n",
    "        hobbies_str = \", \".join([h.get('hobbie_name', '') for h in emp_hobbies_list if h.get('hobbie_name')]) if emp_hobbies_list else None\n",
    "        extra_curricular_str = \", \".join([c.get('curricular', '') for c in emp_curricular_list if c.get('curricular')]) if emp_curricular_list else None\n",
    "        profile_pic_filename = sanitize_filename(data.get('profile_pic'))\n",
    "        profile_pic_path = f\"uploads/profile/{profile_pic_filename}\" if profile_pic_filename else None\n",
    "        signature_filename = sanitize_filename(data.get('emp_signature'))\n",
    "        signature_path = f\"uploads/signature/{signature_filename}\" if signature_filename else None\n",
    "        pan_doc_filename = find_original_filename_from_emp_docs(emp_documents_list, old_internal_emp_id, 'pan', old_table_name='employee_master')\n",
    "        pan_card_file_path = f\"uploads/attachments/{old_internal_emp_id}/{sanitize_filename(pan_doc_filename)}\" if pan_doc_filename and pan_available_bool else None\n",
    "        aadhar_doc_filename = find_original_filename_from_emp_docs(emp_documents_list, old_internal_emp_id, 'aadhaar', old_table_name='employee_master')\n",
    "        aadhar_card_file_path = f\"uploads/attachments/{old_internal_emp_id}/{sanitize_filename(aadhar_doc_filename)}\" if aadhar_doc_filename and aadhar_available_bool else None\n",
    "        dl_doc_filename = find_original_filename_from_emp_docs(emp_documents_list, old_internal_emp_id, 'licence', old_table_name='employee_master')\n",
    "        dl_file_path = f\"uploads/attachments/{old_internal_emp_id}/{sanitize_filename(dl_doc_filename)}\" if dl_doc_filename and dl_available_bool else None\n",
    "        passport_doc_filename = find_original_filename_from_emp_docs(emp_documents_list, old_internal_emp_id, 'passport', old_table_name='employee_master')\n",
    "        passport_file_path = f\"uploads/attachments/{old_internal_emp_id}/{sanitize_filename(passport_doc_filename)}\" if passport_doc_filename and passport_available_bool else None\n",
    "        registration_date_formatted = format_date(data.get('registration_date'), input_formats=['%Y-%m-%d %H:%M:%S', '%d-%b-%Y %H:%M:%S'])\n",
    "        registration_timestamp_val = registration_date_formatted + datetime.now().strftime(\" %H:%M:%S\") if registration_date_formatted else datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "        sql_insert_user = \"\"\"\n",
    "            INSERT INTO users (\n",
    "                name_as_for_document, salutation, first_name, middle_name, surname, nationality, gender, religion, category_type,\n",
    "                date_of_birth, celebrated_date_of_birth, perm_birth_country, perm_birth_state, perm_birth_city_village,\n",
    "                perm_address_line1, perm_address_line2, perm_address_line3, present_birth_country, present_birth_state,\n",
    "                present_birth_city_village, present_address_line1, present_address_line2, present_address_line3,\n",
    "                blood_group, weight_kg, height_cm, identification_marks, pan_available, pan_card_no, pan_card_file_path,\n",
    "                aadhar_available, aadhar_number, aadhar_card_file_path, dl_available, dl_number, dl_file_path,\n",
    "                dl_vehicle_type, dl_expiration_date, passport_available, passport_number, passport_file_path,\n",
    "                passport_expiration_date, profile_picture_path, signature_path, marital_status, your_email_id,\n",
    "                your_phone_number, emergency_contact_number, has_past_experience, has_pf_account, pf_account_established_code,\n",
    "                pf_uan_no, pf_esi_no, extra_curricular_activities, hobbies, medical_disability_exists,\n",
    "                medical_disability_details, prev_employer_liability_exists, prev_employer_liability_details,\n",
    "                worked_simplex_group, agree_posted_anywhere_india, declaration_agreed, registration_timestamp \n",
    "            ) VALUES (%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s)\n",
    "        \"\"\"\n",
    "        user_values = (\n",
    "            data.get('name_as_for'), data.get('empSalutation'), data.get('empFirstName','').strip(), data.get('empMiddleName') or None, data.get('empSurname') or None,\n",
    "            data.get('nationality'), data.get('gender'), data.get('religion'), data.get('cast_category'),\n",
    "            format_date(data.get('emp_dob')), format_date(data.get('emp_dobClb')),\n",
    "            get_lookup_value(data.get('dob_country'), 'country'), get_lookup_value(data.get('dob_state'), 'state'), data.get('dob_city'),\n",
    "            ( (data.get('permanent_hno') or '') + ' ' + (data.get('permanent_streetno') or '') + ' ' + (data.get('permanent_addr') or '')).strip() or None,\n",
    "            None, data.get('permanent_pin'),\n",
    "            get_lookup_value(data.get('present_country'), 'country'), get_lookup_value(data.get('present_state'), 'state'), data.get('present_city'),\n",
    "            ( (data.get('present_hno') or '') + ' ' + (data.get('present_streetno') or '') + ' ' + (data.get('present_addr') or '')).strip() or None,\n",
    "            None, data.get('present_pin'),\n",
    "            data.get('blood_group', '').replace(' ', '') if data.get('blood_group') else None,\n",
    "            float(data.get('emp_weight')) if data.get('emp_weight') and str(data.get('emp_weight')).replace('.','',1).isdigit() else None,\n",
    "            float(data.get('emp_height')) if data.get('emp_height') and str(data.get('emp_height')).replace('.','',1).isdigit() else None,\n",
    "            data.get('identification'),\n",
    "            pan_available_bool, data.get('pan_no') if pan_available_bool else None, pan_card_file_path,\n",
    "            aadhar_available_bool, data.get('aadhaar_no') if aadhar_available_bool else None, aadhar_card_file_path,\n",
    "            dl_available_bool, data.get('licence_no') if dl_available_bool else None, dl_file_path, data.get('vehicle_type') if dl_available_bool else None, format_date(data.get('licence_expiry')) if dl_available_bool else None,\n",
    "            passport_available_bool, data.get('passport_no') if passport_available_bool else None, passport_file_path, format_date(data.get('passport_expiry')) if passport_available_bool else None,\n",
    "            profile_pic_path, signature_path,\n",
    "            data.get('marital_status'),\n",
    "            contact_info.get('Personal_Email', data.get('User_Name')), \n",
    "            contact_info.get('Personal_Mobile', contact_info.get('Personal_Phone')), \n",
    "            None, \n",
    "            has_past_experience_bool, has_pf_account_bool, data.get('pf_account') if has_pf_account_bool else None, \n",
    "            data.get('uan_no') if has_pf_account_bool else None, data.get('esi_no') if has_pf_account_bool else None,\n",
    "            extra_curricular_str, hobbies_str,\n",
    "            medical_disability_exists_bool, data.get('medical_disability_detail') if medical_disability_exists_bool else None,\n",
    "            prev_employer_liability_exists_bool, data.get('libility_detail') if prev_employer_liability_exists_bool else None,\n",
    "            worked_simplex_group_bool, agree_posted_anywhere_india_bool,\n",
    "            declaration_agreed_bool, registration_timestamp_val\n",
    "        )\n",
    "        cursor.execute(sql_insert_user, user_values)\n",
    "        new_user_id = cursor.lastrowid \n",
    "        print(f\"-> Inserted base user with new_user_id: {new_user_id}\")\n",
    "\n",
    "        # --- II. spouse_details Table ---\n",
    "        if data.get('marital_status') in ['Married', 'Registered Partnership'] :\n",
    "            spouse_name_from_master = ( (data.get('fatherSpouseFirstName') or '') + ' ' + (data.get('fatherSpouseMiddleName') or '') + ' ' + (data.get('fatherSpouseSurname') or '') ).strip()\n",
    "            spouse_salutation_from_master = data.get('fatherSpouseSalutation')\n",
    "            spouse_data_to_insert = {'salutation': spouse_salutation_from_master, 'name': spouse_name_from_master, 'mobile_number': None, 'date_of_birth': None, 'aadhar_no': None, 'occupation': None, 'address': None, 'is_nominee_pf': 0, 'is_nominee_esic': 0, 'is_dependent': 0 }\n",
    "            found_spouse_in_family = False\n",
    "            for family_member in emp_family_list:\n",
    "                if str(family_member.get('emp_id')) == str(old_internal_emp_id) and family_member.get('member_relation', '').lower() == 'spouse': \n",
    "                    spouse_data_to_insert['name'] = family_member.get('member_name', spouse_name_from_master)\n",
    "                    spouse_data_to_insert['salutation'] = family_member.get('member_salutation', spouse_salutation_from_master)\n",
    "                    spouse_data_to_insert['mobile_number'] = family_member.get('member_contact')\n",
    "                    spouse_data_to_insert['date_of_birth'] = format_date(family_member.get('member_dob'))\n",
    "                    spouse_data_to_insert['aadhar_no'] = family_member.get('member_aadhaar')\n",
    "                    spouse_data_to_insert['occupation'] = family_member.get('member_occupation')\n",
    "                    spouse_data_to_insert['address'] = family_member.get('member_address')\n",
    "                    spouse_data_to_insert['is_nominee_pf'] = to_boolean(family_member.get('pf_nominee'))\n",
    "                    spouse_data_to_insert['is_nominee_esic'] = to_boolean(family_member.get('esic_nominee'))\n",
    "                    spouse_data_to_insert['is_dependent'] = to_boolean(family_member.get('dependent'))\n",
    "                    found_spouse_in_family = True\n",
    "                    break\n",
    "            if spouse_data_to_insert['name']: \n",
    "                sql_insert_spouse = \"INSERT INTO spouse_details (user_id, salutation, name, mobile_number, date_of_birth, aadhar_no, occupation, address, is_nominee_pf, is_nominee_esic, is_dependent) VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)\"\n",
    "                spouse_values = (new_user_id, spouse_data_to_insert['salutation'], spouse_data_to_insert['name'], spouse_data_to_insert['mobile_number'], spouse_data_to_insert['date_of_birth'], spouse_data_to_insert['aadhar_no'], spouse_data_to_insert['occupation'], spouse_data_to_insert['address'], spouse_data_to_insert['is_nominee_pf'], spouse_data_to_insert['is_nominee_esic'], spouse_data_to_insert['is_dependent'])\n",
    "                cursor.execute(sql_insert_spouse, spouse_values)\n",
    "                print(f\"-> Inserted spouse details.\")\n",
    "\n",
    "        # --- III. parent_details Table ---\n",
    "        for family_member in emp_family_list:\n",
    "            if str(family_member.get('emp_id')) == str(old_internal_emp_id) and family_member.get('member_relation', '').lower() in ['father', 'mother']:\n",
    "                parent_type = family_member.get('member_relation', '').capitalize()\n",
    "                parent_name = family_member.get('member_name') \n",
    "                parent_salutation = family_member.get('member_salutation')\n",
    "                parent_mobile = family_member.get('member_contact')\n",
    "                parent_dob = format_date(family_member.get('member_dob'))\n",
    "                parent_aadhar = family_member.get('member_aadhaar')\n",
    "                parent_aadhar_doc_filename = find_original_filename_from_emp_docs(emp_documents_list, old_internal_emp_id, 'family', family_member.get('member_id'), 'emp_family')\n",
    "                parent_aadhar_file = f\"uploads/attachments/{old_internal_emp_id}/{sanitize_filename(parent_aadhar_doc_filename)}\" if parent_aadhar_doc_filename else None\n",
    "                parent_occupation = family_member.get('member_occupation')\n",
    "                parent_address = family_member.get('member_address')\n",
    "                parent_nom_pf = to_boolean(family_member.get('pf_nominee'))\n",
    "                parent_nom_esic = to_boolean(family_member.get('esic_nominee'))\n",
    "                parent_dependent = to_boolean(family_member.get('dependent'))\n",
    "                sql_insert_parent = \"INSERT INTO parent_details (user_id, parent_type, salutation, name, mobile_number, date_of_birth, aadhar_no, aadhar_file_path, occupation, address, is_nominee_pf, is_nominee_esic, is_dependent) VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)\"\n",
    "                parent_values = (new_user_id, parent_type, parent_salutation, parent_name, parent_mobile, parent_dob, parent_aadhar, parent_aadhar_file, parent_occupation, parent_address, parent_nom_pf, parent_nom_esic, parent_dependent)\n",
    "                cursor.execute(sql_insert_parent, parent_values)\n",
    "        print(f\"-> Processed parent details from emp_family.\")\n",
    "\n",
    "        # --- IV. user_education Table ---\n",
    "        for edu_record in emp_education_list:\n",
    "            if str(edu_record.get('emp_id')) == str(old_internal_emp_id):\n",
    "                edu_doc_filename = find_original_filename_from_emp_docs(emp_documents_list, old_internal_emp_id, 'education', edu_record.get('eid'), 'emp_education')\n",
    "                edu_doc_path = f\"uploads/attachments/{old_internal_emp_id}/{sanitize_filename(edu_doc_filename)}\" if edu_doc_filename else None\n",
    "                sql_edu = \"INSERT INTO user_education (user_id, qualification, board_university, subject, enrollment_year, passing_year, percentage_grade, document_path) VALUES (%s, %s, %s, %s, %s, %s, %s, %s)\"\n",
    "                edu_values = (new_user_id, edu_record.get('education_type'), edu_record.get('university'), edu_record.get('major_subject'), edu_record.get('from_year'), edu_record.get('to_year'), edu_record.get('gradepoint'), edu_doc_path)\n",
    "                cursor.execute(sql_edu, edu_values)\n",
    "        print(f\"-> Processed {len(emp_education_list)} education records.\")\n",
    "\n",
    "        # --- V. user_certifications Table --- \n",
    "        for cert_record in emp_certification_list:\n",
    "            if str(cert_record.get('emp_id')) == str(old_internal_emp_id):\n",
    "                cert_doc_filename = find_original_filename_from_emp_docs(emp_documents_list, old_internal_emp_id, 'certification', cert_record.get('cid'), 'emp_certification') \n",
    "                cert_doc_path = f\"uploads/attachments/{old_internal_emp_id}/{sanitize_filename(cert_doc_filename)}\" if cert_doc_filename else None\n",
    "                sql_cert = \"INSERT INTO user_certifications (user_id, certificate_name, issued_on, valid_upto, certificate_authority, document_path) VALUES (%s, %s, %s, %s, %s, %s)\"\n",
    "                cert_values = (new_user_id, cert_record.get('certificate_name'), format_date(cert_record.get('issued_on')), format_date(cert_record.get('valid_upto')), cert_record.get('certificate_authority'), cert_doc_path)\n",
    "                cursor.execute(sql_cert, cert_values)\n",
    "        print(f\"-> Processed {len(emp_certification_list)} certification records.\")\n",
    "\n",
    "        # --- VI. user_work_experience Table ---\n",
    "        for exp_record in emp_experience_list:\n",
    "            if str(exp_record.get('emp_id')) == str(old_internal_emp_id):\n",
    "                exp_letter_filename = find_original_filename_from_emp_docs(emp_documents_list, old_internal_emp_id, 'experience_letter', exp_record.get('exp_id'), 'emp_experience') # CORRECTED TYPO\n",
    "                exp_letter_path = f\"uploads/attachments/{old_internal_emp_id}/{sanitize_filename(exp_letter_filename)}\" if exp_letter_filename else None\n",
    "                sql_exp = \"INSERT INTO user_work_experience (user_id, company_name, designation, reason_for_leaving, salary_per_annum, roles_responsibility, competency, from_date, to_date, employer_contact_no, experience_letter_path) VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)\"\n",
    "                exp_values = (new_user_id, exp_record.get('company_name'), exp_record.get('designation'), exp_record.get('leaving_resion'), exp_record.get('salary'), exp_record.get('roles_responsibility'), exp_record.get('competency'), format_date(exp_record.get('from_year')), format_date(exp_record.get('to_year')), exp_record.get('employer_contact'), exp_letter_path)\n",
    "                cursor.execute(sql_exp, exp_values)\n",
    "        print(f\"-> Processed {len(emp_experience_list)} work experience records.\")\n",
    "\n",
    "        # --- VII. user_languages Table ---\n",
    "        for lang_record in emp_languages_list:\n",
    "            if str(lang_record.get('emp_id')) == str(old_internal_emp_id):\n",
    "                sql_lang = \"INSERT INTO user_languages (user_id, language_name, can_speak, can_read, can_write, can_understand) VALUES (%s, %s, %s, %s, %s, %s)\"\n",
    "                lang_values = (new_user_id, lang_record.get('lang_name'), to_boolean(lang_record.get('lang_speak')), to_boolean(lang_record.get('lang_read')), to_boolean(lang_record.get('lang_write')), to_boolean(lang_record.get('lang_understand')))\n",
    "                cursor.execute(sql_lang, lang_values)\n",
    "        print(f\"-> Processed {len(emp_languages_list)} language records.\")\n",
    "\n",
    "        # --- VIII. user_references Table ---\n",
    "        for ref_record in emp_references_list:\n",
    "            if str(ref_record.get('emp_id')) == str(old_internal_emp_id):\n",
    "                sql_ref = \"INSERT INTO user_references (user_id, reference_name, address, designation_position, relation, contact_no) VALUES (%s, %s, %s, %s, %s, %s)\"\n",
    "                ref_values = (new_user_id, ref_record.get('ref_name'), ref_record.get('ref_address'), ref_record.get('ref_designation'), ref_record.get('ref_relation'), ref_record.get('ref_contact'))\n",
    "                cursor.execute(sql_ref, ref_values)\n",
    "        print(f\"-> Processed {len(emp_references_list)} reference records.\")\n",
    "        \n",
    "        # --- IX. user_bank_details Table ---\n",
    "        if data.get('bank_name'): \n",
    "            bank_passbook_filename = find_original_filename_from_emp_docs(emp_documents_list, old_internal_emp_id, 'passbook', old_table_name='employee_master') \n",
    "            bank_passbook_path = f\"uploads/attachments/{old_internal_emp_id}/{sanitize_filename(bank_passbook_filename)}\" if bank_passbook_filename else None\n",
    "            sql_insert_bank = \"INSERT INTO user_bank_details (user_id, bank_name, account_number, ifsc_code, micr_code, bank_address, passbook_document_path) VALUES (%s, %s, %s, %s, %s, %s, %s)\"\n",
    "            bank_values = (new_user_id, data.get('bank_name'), data.get('bank_account'), data.get('ifsc_no'), data.get('micr_code'), data.get('bank_addr'), bank_passbook_path)\n",
    "            cursor.execute(sql_insert_bank, bank_values)\n",
    "            print(\"-> Inserted bank details.\")\n",
    "\n",
    "        # --- X. user_hr_details Table ---\n",
    "        sql_insert_hr = \"INSERT INTO user_hr_details (user_id, unit, department, designation, date_of_joining, category, grade, status, leave_group, shift_schedule, reporting_incharge, department_head, attendance_policy, employee_id_ascent, employee_role, payroll_code, vaccination_code, employee_portal_status) VALUES (%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s)\"\n",
    "        hr_values = (\n",
    "            new_user_id, data.get('unit'), data.get('department'), data.get('postName'), \n",
    "            format_date(data.get('joiningDate')), data.get('Category'), data.get('grade'),     \n",
    "            data.get('ascent_status'), data.get('leave_group'), data.get('shift_schedule'), data.get('Reporting_group'),\n",
    "            data.get('emp_head_id'), data.get('attendance_policy'), employee_id_ascent_val, \n",
    "            'USER', data.get('payroll_code'), data.get('vacci_code'),\n",
    "            data.get('emp_status')\n",
    "        )\n",
    "        cursor.execute(sql_insert_hr, hr_values)\n",
    "        print(\"-> Inserted HR details.\")\n",
    "        \n",
    "        # --- XI. user_it_details Table ---\n",
    "        it_official_phone = contact_info.get('Official_Mobile', contact_info.get('Official_Phone'))\n",
    "        it_official_email = contact_info.get('Official_Email')\n",
    "        it_intercom_number = contact_info.get('Official_Extn')\n",
    "        if it_official_phone or it_official_email or it_intercom_number:\n",
    "            sql_insert_it = \"INSERT INTO user_it_details (user_id, official_phone_number, official_email, intercom_number) VALUES (%s, %s, %s, %s)\"\n",
    "            it_values = (new_user_id, it_official_phone, it_official_email, it_intercom_number)\n",
    "            cursor.execute(sql_insert_it, it_values)\n",
    "            print(\"-> Inserted IT details.\")\n",
    "        \n",
    "        conn.commit()\n",
    "        print(f\"-> Successfully migrated data for old internal emp_id: {old_internal_emp_id}\")\n",
    "        return True\n",
    "\n",
    "    except mysql.connector.Error as err:\n",
    "        print(f\"Database error during migration for old internal emp_id {old_internal_emp_id}: {err}\")\n",
    "        if conn.is_connected(): conn.rollback()\n",
    "        return False\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred for old internal emp_id {old_internal_emp_id}: {e}\")\n",
    "        if conn.is_connected(): conn.rollback()\n",
    "        return False\n",
    "    finally:\n",
    "        if conn and conn.is_connected():\n",
    "            cursor.close()\n",
    "            conn.close()\n",
    "\n",
    "# --- Main Execution Block ---\n",
    "if __name__ == \"__main__\":\n",
    "    if not reset_database_tables():\n",
    "        print(\"\\nHalting migration due to database reset failure.\")\n",
    "        exit()\n",
    "\n",
    "    unified_json_file_path = \"json/full_employee_json_data.json\" \n",
    "    \n",
    "    try:\n",
    "        with open(unified_json_file_path, 'r', encoding='utf-8') as f:\n",
    "            all_employees_data_from_file = json.load(f)\n",
    "        print(f\"Successfully loaded unified JSON file: {unified_json_file_path}\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: Unified JSON file not found - {unified_json_file_path}.\")\n",
    "        exit()\n",
    "    except json.JSONDecodeError:\n",
    "        print(f\"Error: Could not decode JSON from file - {unified_json_file_path}\")\n",
    "        exit()\n",
    "\n",
    "    if not isinstance(all_employees_data_from_file, dict):\n",
    "        print(f\"Error: Unified JSON file is not a dictionary.\")\n",
    "        exit()\n",
    "\n",
    "    total_employees = len(all_employees_data_from_file)\n",
    "    success_count = 0\n",
    "    failure_count = 0\n",
    "    failed_entries = [] # List to store the IDs of failed entries\n",
    "\n",
    "    print(f\"\\nStarting migration for {total_employees} employee(s)...\")\n",
    "\n",
    "    for old_emp_id_key, employee_data_struct in all_employees_data_from_file.items():\n",
    "        if migrate_employee_data(employee_data_struct):\n",
    "            success_count += 1\n",
    "        else:\n",
    "            failure_count += 1\n",
    "            failed_entries.append(old_emp_id_key) # Add the failed ID to the list\n",
    "        print(\"-\" * 50)\n",
    "\n",
    "    print(\"\\n--- Migration Summary ---\")\n",
    "    print(f\"Total entries in JSON: {total_employees}\")\n",
    "    print(f\"Successfully migrated: {success_count}\")\n",
    "    print(f\"Failed or skipped: {failure_count}\")\n",
    "\n",
    "    if failed_entries:\n",
    "        print(\"\\n--- Failed or Skipped emp_id's ---\")\n",
    "        # Print the list of failed IDs, 10 per line for readability\n",
    "        for i in range(0, len(failed_entries), 10):\n",
    "             print(\", \".join(failed_entries[i:i+10]))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
